{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-04T07:39:32.721762Z","iopub.execute_input":"2022-01-04T07:39:32.722058Z","iopub.status.idle":"2022-01-04T07:39:32.727392Z","shell.execute_reply.started":"2022-01-04T07:39:32.722032Z","shell.execute_reply":"2022-01-04T07:39:32.726799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom os.path import join\n\nimport numpy as np\nimport pandas as pd\n\nfrom scipy.spatial import distance_matrix\n\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\n\ntry:\n    import dgl\nexcept:\n    !pip install dgl\n    import dgl\n    \nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-01-04T09:04:33.521332Z","iopub.execute_input":"2022-01-04T09:04:33.521806Z","iopub.status.idle":"2022-01-04T09:04:45.440985Z","shell.execute_reply.started":"2022-01-04T09:04:33.521751Z","shell.execute_reply":"2022-01-04T09:04:45.440151Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2022-01-04T09:04:45.442821Z","iopub.execute_input":"2022-01-04T09:04:45.443030Z","iopub.status.idle":"2022-01-04T09:04:45.447661Z","shell.execute_reply.started":"2022-01-04T09:04:45.443002Z","shell.execute_reply":"2022-01-04T09:04:45.446821Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import dgl.data\n\ndataset = dgl.data.CoraGraphDataset()\nprint('Number of categories:', dataset.num_classes)","metadata":{"execution":{"iopub.status.busy":"2022-01-04T09:04:52.449336Z","iopub.execute_input":"2022-01-04T09:04:52.449684Z","iopub.status.idle":"2022-01-04T09:04:53.360261Z","shell.execute_reply.started":"2022-01-04T09:04:52.449655Z","shell.execute_reply":"2022-01-04T09:04:53.359394Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"g=dataset[0]\nfrom dgl.nn import GraphConv\n\nclass GCN(nn.Module):\n    def __init__(self, in_feats,o_feats ,h_feats, num_classes):\n        super(GCN, self).__init__()\n        self.conv1 = GraphConv(in_feats, o_feats)\n        self.conv2 = GraphConv(o_feats, h_feats)\n        self.conv3 = GraphConv(h_feats, num_classes)\n    def forward(self, g, in_feat):\n        h = self.conv1(g, in_feat)\n        h = F.leaky_relu(h)\n        h = self.conv2(g,h) \n        h = F.relu(h)\n        h = self.conv3(g, h)\n        return h\n\n# Create the model with given dimensions\nmodel = GCN(g.ndata['feat'].shape[1], 64, 16, dataset.num_classes)","metadata":{"execution":{"iopub.status.busy":"2022-01-04T09:04:58.158757Z","iopub.execute_input":"2022-01-04T09:04:58.159027Z","iopub.status.idle":"2022-01-04T09:04:58.179438Z","shell.execute_reply.started":"2022-01-04T09:04:58.158999Z","shell.execute_reply":"2022-01-04T09:04:58.178501Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"test_score = []\nlosses = []\nvalidation_score = []\ntrain_score = []\ndef train(g, model):\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n    best_val_acc = 0\n    best_test_acc = 0\n\n    features = g.ndata['feat']\n    labels = g.ndata['label']\n    train_mask = g.ndata['train_mask']\n    val_mask = g.ndata['val_mask']\n    test_mask = g.ndata['test_mask']\n    for e in range(500):\n        # Forward\n        logits = model(g, features)\n\n        # Compute prediction\n        pred = logits.argmax(1)\n\n        # Compute loss\n        # Note that you should only compute the losses of the nodes in the training set.\n        loss = F.cross_entropy(logits[train_mask], labels[train_mask])\n        losses.append(loss)\n        # Compute accuracy on training/validation/test\n        train_acc = (pred[train_mask] == labels[train_mask]).float().mean()\n        val_acc = (pred[val_mask] == labels[val_mask]).float().mean()\n        test_acc = (pred[test_mask] == labels[test_mask]).float().mean()\n        #storing the metrics in lists format\n        train_score.append(train_acc)\n        validation_score.append(val_acc)\n        test_score.append(test_acc)\n        # Save the best validation accuracy and the corresponding test accuracy.\n        if best_val_acc < val_acc:\n            best_val_acc = val_acc\n            best_test_acc = test_acc\n\n        # Backward\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if e % 20 == 0:\n            print('In epoch {}, loss: {:.3f}, val acc: {:.3f} (best {:.3f}), test acc: {:.3f} (best {:.3f})'.format(\n                e, loss, val_acc, best_val_acc, test_acc, best_test_acc))\nmodel = GCN(g.ndata['feat'].shape[1], 64 ,16, dataset.num_classes)\ntrain(g, model)","metadata":{"execution":{"iopub.status.busy":"2022-01-04T09:05:03.172042Z","iopub.execute_input":"2022-01-04T09:05:03.172440Z","iopub.status.idle":"2022-01-04T09:05:15.123725Z","shell.execute_reply.started":"2022-01-04T09:05:03.172389Z","shell.execute_reply":"2022-01-04T09:05:15.122757Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-01-04T09:05:39.646920Z","iopub.execute_input":"2022-01-04T09:05:39.647275Z","iopub.status.idle":"2022-01-04T09:05:39.665529Z","shell.execute_reply.started":"2022-01-04T09:05:39.647231Z","shell.execute_reply":"2022-01-04T09:05:39.664740Z"},"trusted":true},"execution_count":7,"outputs":[]}]}